{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>url</th>\n",
                            "      <th>is_spam</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>https://briefingday.us8.list-manage.com/unsubs...</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>https://www.hvper.com/</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>https://briefingday.com/m/v4n3i4f3</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>https://briefingday.com/n/20200618/m#commentform</td>\n",
                            "      <td>False</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>https://briefingday.com/fan</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                 url  is_spam\n",
                            "0  https://briefingday.us8.list-manage.com/unsubs...     True\n",
                            "1                             https://www.hvper.com/     True\n",
                            "2                 https://briefingday.com/m/v4n3i4f3     True\n",
                            "3   https://briefingday.com/n/20200618/m#commentform    False\n",
                            "4                        https://briefingday.com/fan     True"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Your code here\n",
                "import pandas as pd\n",
                "\n",
                "df = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/NLP-project-tutorial/main/url_spam.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "unmatched ')' (46294796.py, line 1)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    df['is_spam'] = df['is_spam'].apply(lamda x: 1 if x else 0).astype(int))\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
                    ]
                }
            ],
            "source": [
                "df['is_spam'] = df['is_spam'].apply(lamda x: 1 if x else 0).astype(int)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f'Antes de duplicados {df.shape}')\n",
                "df = df.drop_duplicates()\n",
                "df = df.reset_index(inplace=False, drop=True)\n",
                "df.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Spam: {len(df.loc[df.is_spam == 1])}\")\n",
                "print(f\"No spam: {len(df.loc[df.is_spam == 0])}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import regex as re\n",
                "\n",
                "def preprocess_text(text):\n",
                "    # Eliminar cualquier caracter que no sea una letra (a-z) o un espacio en blanco ( )\n",
                "    text = re.sub(r'[^a-z ]', \" \", text)\n",
                "    \n",
                "    # Eliminar espacios en blanco\n",
                "    text = re.sub(r'\\s+[a-zA-Z]\\s+', \" \", text)\n",
                "    text = re.sub(r'\\^[a-zA-Z]\\s+', \" \", text)\n",
                "\n",
                "    # Reducir espacios en blanco múltiples a uno único\n",
                "    text = re.sub(r'\\s+', \" \", text.lower())\n",
                "\n",
                "    # Eliminar tags\n",
                "    text = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \", text)\n",
                "\n",
                "    return text.split()\n",
                "\n",
                "df[\"url\"] = total_data[\"url\"].apply(preprocess_text)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from nltk import download\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "\n",
                "download(\"wordnet\")\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "download(\"stopwords\")\n",
                "stop_words = stopwords.words(\"english\")\n",
                "\n",
                "def lemmatize_text(words, lemmatizer = lemmatizer):\n",
                "    tokens = [lemmatizer.lemmatize(word) for word in words]\n",
                "    tokens = [word for word in tokens if word not in stop_words]\n",
                "    tokens = [word for word in tokens if len(word) > 3]\n",
                "    return tokens\n",
                "\n",
                "df[\"url\"] = df[\"url\"].apply(lemmatize_text)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from wordcloud import WordCloud\n",
                "\n",
                "wordcloud = WordCloud(width = 800, height = 800, background_color = \"black\", max_words = 1000, min_font_size = 20, random_state = 42)\\\n",
                "    .generate(str(df[\"url\"]))\n",
                "\n",
                "fig = plt.figure(figsize = (8, 8), facecolor = None)\n",
                "plt.imshow(wordcloud)\n",
                "plt.axis(\"off\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "tokens_list = df[\"url\"]\n",
                "tokens_list = [\" \".join(tokens) for tokens in tokens_list]\n",
                "\n",
                "vectorizer = TfidfVectorizer(max_features = 5000, max_df = 0.8, min_df = 5)\n",
                "X = vectorizer.fit_transform(tokens_list).toarray()\n",
                "y = df[\"is_spam\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.svm import SVC\n",
                "\n",
                "model = SVC(kernel = \"linear\", random_state = 42)\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = model.predict(X_test)\n",
                "y_pred"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pickle import dump\n",
                "\n",
                "dump(model, open(\"svm_classifier_linear_42.sav\", \"wb\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
